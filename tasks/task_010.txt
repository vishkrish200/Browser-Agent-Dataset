# Task ID: 10
# Title: Develop JSONL Dataset Builder
# Status: pending
# Dependencies: 5, 6, 7
# Priority: high
# Description: Create a module to transform collected and processed data into JSONL format suitable for LLM fine-tuning.
# Details:
1. Create a `dataset_builder.py` module with DatasetBuilder class
2. Implement JSONL generation:
   - Format: `<DOM>...HTML content...</DOM><ACTION>click #selector</ACTION>`
   - Optional image format: Include `<IMAGE>s3://path/to/image.webp</IMAGE>`
3. Add filtering options:
   - By site/domain
   - By workflow type
   - By action type
   - By success/failure
4. Implement train/validation split functionality
5. Add dataset statistics generation

Example usage:
```python
from dataset_builder import DatasetBuilder

builder = DatasetBuilder()
builder.build_dataset(
    input_path="s3://checkpoints/",
    output_path="./datasets/",
    include_images=True,
    train_split=0.9
)
```

# Test Strategy:
Unit tests for JSONL formatting and dataset building logic. Test with sample data to verify output format. Verify train/validation splits work correctly. Test statistics generation for accuracy.

# Subtasks:
## 1. Set up modular project structure [done]
### Dependencies: None
### Description: Create a modular project structure with separate components for data processing, transformation, and analysis
### Details:
Implement a modular design pattern following data engineering best practices. Create separate modules for each functional component with clear interfaces between them. Set up version control for tracking schema changes and code evolution.
<info added on 2025-05-14T18:34:37.692Z>
Implement a modular design pattern following data engineering best practices. Create separate modules for each functional component with clear interfaces between them. Set up version control for tracking schema changes and code evolution.

For the JSONL Dataset Builder project, implement the following structure:

1. Source Directory Structure (src/dataset_builder/):
   - __init__.py
   - builder.py (for DatasetBuilder class)
   - config.py (for module-specific settings)
   - exceptions.py (for custom error handling)
   - types.py (for data structures like Pydantic models/TypedDicts)
   - utils.py (for utility functions)
   - formatting.py (for JSONL formatting logic)
   - filtering.py (for dataset filtering capabilities)
   - splitting.py (for train/test/validation splitting)
   - statistics.py (for dataset analytics)
   - image_handler.py (for image processing logic)

2. Test Directory Structure (tests/dataset_builder/):
   - __init__.py
   - test_builder.py
   - test_formatting.py
   - test_filtering.py
   - test_splitting.py
   - test_statistics.py
   - test_image_handler.py

3. Initial File Content:
   - Create empty __init__.py files for proper Python package structure
   - Implement basic class definition for DatasetBuilder in builder.py
   - Define custom exceptions in exceptions.py (e.g., DatasetBuilderError)
   - Add placeholder functions with type hints in other modules

This structure will support the subsequent task of implementing the JSONL formatting module (subtask 10.2) by providing the necessary scaffolding and separation of concerns.
</info added on 2025-05-14T18:34:37.692Z>
<info added on 2025-05-14T18:55:35.150Z>
All placeholder files have been created according to the planned structure. The implementation includes:

1. Source Directory (src/dataset_builder/):
   - __init__.py: Package initialization
   - builder.py: Contains DatasetBuilder class skeleton
   - config.py: Module configuration settings
   - exceptions.py: Custom exception definitions
   - types.py: Type definitions and data structures
   - utils.py: Utility functions
   - formatting.py: JSONL formatting logic (placeholder)
   - filtering.py: Dataset filtering capabilities (placeholder)
   - splitting.py: Train/test/validation splitting (placeholder)
   - statistics.py: Dataset analytics (placeholder)
   - image_handler.py: Image processing logic (placeholder)

2. Test Directory (tests/dataset_builder/):
   - __init__.py: Test package initialization
   - test_builder.py: Tests for DatasetBuilder class
   - test_config.py: Tests for configuration module
   - test_formatting.py: Tests for JSONL formatting
   - test_filtering.py: Tests for filtering capabilities
   - test_splitting.py: Tests for dataset splitting
   - test_statistics.py: Tests for analytics functions
   - test_image_handler.py: Tests for image processing
   - test_utils.py: Tests for utility functions

Note: test_exceptions.py and test_types.py were not created at this stage as the source files contain basic definitions that don't require immediate testing.

The modular structure is now ready for implementing the JSONL formatting module (subtask 10.2) with all necessary scaffolding in place.
</info added on 2025-05-14T18:55:35.150Z>

## 2. Implement JSONL formatting module [done]
### Dependencies: 10.1
### Description: Develop a module to handle JSONL data formatting and validation
### Details:
Create functions to parse, validate, and format data in JSONL format. Implement schema validation to ensure data consistency and quality. Include error handling for malformed JSON entries.
<info added on 2025-05-14T19:27:07.726Z>
Create functions to parse, validate, and format data in JSONL format. Implement schema validation to ensure data consistency and quality. Include error handling for malformed JSON entries.

Implementation details:
1. Defined Pydantic models in types.py:
   - ProcessedDataRecord: Main data structure based on PRD requirements
   - ActionDetail: Supporting model for action-related data

2. Implemented core functions in formatting.py:
   - create_processed_data_record(): Creates and validates ProcessedDataRecord instances
   - serialize_record_to_jsonl(): Converts validated records to JSONL strings
   - format_for_llm_prompt_completion(): Conceptual function for LLM-specific formatting
   - DataFormattingError: Custom exception class for error handling

3. Created comprehensive test suite in test_formatting.py:
   - Tests for successful record creation
   - Validation error tests (invalid URL, S3 path, malformed action)
   - Serialization tests
   - LLM formatting examples

The module now provides robust JSONL handling with strong validation and error handling capabilities.
</info added on 2025-05-14T19:27:07.726Z>

## 3. Build data filtering component [done]
### Dependencies: 10.2
### Description: Create a component to filter data based on specified criteria
### Details:
Develop filtering logic with configurable parameters. Implement both inclusive and exclusive filtering capabilities. Ensure the component can handle large datasets efficiently through streaming or batch processing.
<info added on 2025-05-14T19:29:20.484Z>
Develop filtering logic with configurable parameters. Implement both inclusive and exclusive filtering capabilities. Ensure the component can handle large datasets efficiently through streaming or batch processing.

The implementation has been completed with the creation of a `DataFilterer` class in `filtering.py`. This class provides methods for adding and applying various filter types including:
- URL domain filtering
- Action type filtering
- HTML content regex filtering
- Support for custom callable filters

The component is designed to work with ProcessedDataRecord objects and supports both configurable and extensible filtering capabilities. Comprehensive unit tests have been added in `test_filtering.py` that cover filter logic, filter combinations, and error handling scenarios. The filtering component is now ready for integration with the JSONL dataset builder pipeline.
</info added on 2025-05-14T19:29:20.484Z>

## 4. Develop data splitting functionality [pending]
### Dependencies: 10.3
### Description: Create functionality to split datasets into training, validation, and test sets
### Details:
Implement methods for random, stratified, and time-based splitting. Ensure reproducibility by supporting seed values. Add options for customizing split ratios and maintaining data distribution characteristics.

## 5. Create statistical analysis module [pending]
### Dependencies: 10.2
### Description: Develop a module for calculating and reporting dataset statistics
### Details:
Implement functions to calculate descriptive statistics, identify outliers, and analyze data distributions. Create visualization capabilities for key metrics. Design the module to work efficiently with large datasets.

## 6. Build image processing handler [pending]
### Dependencies: 10.1
### Description: Develop functionality for processing and transforming image data
### Details:
Create components for image loading, resizing, normalization, and augmentation. Implement efficient storage and retrieval mechanisms for image data. Ensure compatibility with common image formats and integration with the JSONL data structure.

## 7. Implement comprehensive testing framework [pending]
### Dependencies: 10.1, 10.2, 10.3, 10.4, 10.5, 10.6
### Description: Create a testing framework for validating all components
### Details:
Develop unit tests for each module and integration tests for the complete pipeline. Implement data quality checks and performance benchmarks. Create automated test workflows to ensure ongoing code quality and functionality.

